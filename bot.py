import asyncio
import aiohttp
from aiogram import Bot, Dispatcher, F
from aiogram.filters import Command
from aiogram.types import InlineKeyboardMarkup, InlineKeyboardButton, InputMediaPhoto, InputMediaDocument, Message, InputFile, CallbackQuery
from aiogram.enums import ContentType
from bs4 import BeautifulSoup
import re
try:
    from PIL import Image  # –¥–ª—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ WEBP ‚Üí JPEG (Telegram –Ω–µ –ø—Ä–∏–Ω–∏–º–∞–µ—Ç webp –∫–∞–∫ —Ñ–æ—Ç–æ)
    PIL_AVAILABLE = True
except Exception:
    PIL_AVAILABLE = False
import logging
from io import BytesIO
from playwright.async_api import async_playwright
import time
from urllib.parse import urljoin, urlparse

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

import os

# –¢–æ–∫–µ–Ω –±–æ—Ç–∞ –∏ ID –∞–¥–º–∏–Ω–∞
API_TOKEN = os.getenv('BOT_TOKEN')
ADMIN_ID = 198711432

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–æ—Ç–∞
bot = Bot(token=API_TOKEN)
dp = Dispatcher()

# –≠–º–æ–¥–∑–∏ –¥–ª—è –∞–Ω–∏–º–∞—Ü–∏–∏ –∑–∞–≥—Ä—É–∑–∫–∏
LOADING_EMOJIS = ['‚è≥', 'üïí', 'üïì']

# –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ (50 –ú–ë –¥–ª—è Telegram)
MAX_FILE_SIZE = 50 * 1024 * 1024  # 50 –ú–ë –≤ –±–∞–π—Ç–∞—Ö

# –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
IMAGE_EXTENSIONS = ('.jpg', '.jpeg', '.png', '.gif', '.webp', '.bmp')
VIDEO_EXTENSIONS = ('.mp4', '.webm', '.mov', '.avi', '.mkv')

# –°—á–µ—Ç—á–∏–∫ –∑–∞–ø—Ä–æ—Å–æ–≤ –∏ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
request_count = 0
user_activity = {}  # {user_id: [timestamp, ...]}

# –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
def update_user_activity(user_id: int):
    current_time = time.time()
    if user_id not in user_activity:
        user_activity[user_id] = []
    user_activity[user_id].append(current_time)
    # –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –º–µ—Ç–æ–∫ (—Å—Ç–∞—Ä—à–µ 7 –¥–Ω–µ–π)
    user_activity[user_id] = [t for t in user_activity[user_id] if t > current_time - 604800]

# –ü–æ–¥—Å—á—ë—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
def get_user_stats():
    now = time.time()
    daily_users = set()
    weekly_users = set()
    total_users = set()
    
    for user_id, timestamps in user_activity.items():
        total_users.add(user_id)
        for t in timestamps:
            if t > now - 86400:  # 24 —á–∞—Å–∞
                daily_users.add(user_id)
            if t > now - 604800:  # 7 –¥–Ω–µ–π
                weekly_users.add(user_id)
    
    return len(daily_users), len(weekly_users), len(total_users)

# –ú–µ–Ω—é –∞–¥–º–∏–Ω-–ø–∞–Ω–µ–ª–∏
def get_admin_menu():
    keyboard = InlineKeyboardMarkup(inline_keyboard=[
        [InlineKeyboardButton("üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π", callback_data="admin_stats")],
        [InlineKeyboardButton("üöÄ –°—Ç–∞—Ç—É—Å –±–æ—Ç–∞", callback_data="admin_status")],
        [InlineKeyboardButton("üîô –ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é", callback_data="main_menu")]
    ])
    return keyboard

# –ü–æ–ø—ã—Ç–∫–∞ —Å–∫–∞—á–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –≤–º–µ—Å—Ç–æ .webp ‚Äî .jpg/.jpeg/.png)
async def fetch_alt_image_format(session: aiohttp.ClientSession, url: str) -> BytesIO | None:
    try:
        lu = (url or '').lower()
        if not lu.endswith('.webp'):
            return None
        for ext in ('.jpg', '.jpeg', '.png'):
            alt = url[:-5] + ext  # –∑–∞–º–µ–Ω—è–µ–º —Å—É—Ñ—Ñ–∏–∫—Å .webp
            try:
                async with session.get(alt, timeout=15) as resp:
                    ctype = (resp.headers.get('content-type') or '').lower()
                    if resp.status == 200 and (ctype.startswith('image/jpeg') or ctype.startswith('image/png')):
                        data = await resp.read()
                        if data:
                            return BytesIO(data)
            except Exception:
                continue
    except Exception:
        return None
    return None

# –û—Ç–ø—Ä–∞–≤–∫–∞ —Å–ø–∏—Å–∫–∞ URL —Å —Ñ–æ—Ç–æ (—Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è, —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ, –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è, –±–∞—Ç—á–∏)
async def process_media_urls(message: Message, urls: list[str], loading_msg: Message, source_hint: str = ""):
    try:
        # –°–ø–µ—Ü-—Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –¥–ª—è easyhata
        photo_urls = []
        try:
            parsed = urlparse(source_hint or "")
            host = (parsed.netloc or '').lower()
            obj_id = None
            m = re.search(r"/flats/(\d+)/", parsed.path or '')
            if m:
                obj_id = m.group(1)
            def is_target(u: str) -> bool:
                lu = (u or '').lower()
                if any(x in lu for x in ['.svg', 'favicon.ico', '/avatar/']):
                    return False
                if (('easybase.b-cdn.net' in lu and '/realty/' in lu) or ('api.easybase.com.ua' in lu and '/media/realty/' in lu)):
                    if obj_id and f"/{obj_id}/" in lu:
                        return True
                    return True
                return True  # –Ω–µ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª—è –¥—Ä—É–≥–∏—Ö –¥–æ–º–µ–Ω–æ–≤
            if 'easyhata.site' in host:
                urls = [u for u in urls if is_target(u)]
        except Exception:
            pass

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (–º—è–≥–∫–∞—è)
        async with aiohttp.ClientSession() as session:
            for u in urls:
                lu = u.lower()
                if ((('easybase.b-cdn.net' in lu and '/realty/' in lu) or ('api.easybase.com.ua' in lu and '/media/realty/' in lu))
                    and not any(x in lu for x in ['.svg', 'favicon.ico', '/avatar/'])):
                    photo_urls.append(u)
                    continue
                if get_media_type(u) == 'photo' or await is_image_url(session, u):
                    photo_urls.append(u)

        if not photo_urls:
            if loading_msg:
                try:
                    await loading_msg.delete()
                except Exception:
                    pass
            await message.reply("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏. üö´", reply_markup=get_main_menu())
            return

        media: list[InputMediaPhoto] = []
        doc_fallbacks: list[tuple[BytesIO, str]] = []
        async with aiohttp.ClientSession() as session:
            for i, url in enumerate(photo_urls, 1):
                photo_data, error = await download_media(url, session)
                if not photo_data:
                    continue
                if photo_data.getbuffer().nbytes <= 0:
                    continue
                # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –ø—ã—Ç–∞–µ–º—Å—è –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –≤ JPEG (–Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞)
                # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –¥–æ—Å—Ç–∞—Ç—å –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π JPEG/PNG –Ω–∞–ø—Ä—è–º—É—é —Å CDN
                try:
                    alt_buf = await fetch_alt_image_format(session, url)
                    if alt_buf is not None:
                        photo_data = alt_buf
                except Exception:
                    pass
                if PIL_AVAILABLE:
                    try:
                        photo_data.seek(0)
                        img = Image.open(photo_data)
                        # –ï—Å–ª–∏ –∞–Ω–∏–º–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ, –±–µ—Ä—ë–º –ø–µ—Ä–≤—ã–π –∫–∞–¥—Ä
                        try:
                            if getattr(img, 'is_animated', False):
                                img.seek(0)
                        except Exception:
                            pass
                        if img.mode in ('RGBA', 'P'):
                            img = img.convert('RGB')
                        buf = BytesIO()
                        img.save(buf, format='JPEG', quality=90)
                        buf.seek(0)
                        media.append(InputMediaPhoto(media=InputFile(buf, filename=f"photo_{i}.jpg")))
                        continue
                    except Exception as ce:
                        logging.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –≤ JPEG {url}: {ce}")
                        # –ø–æ–π–¥—ë–º –≤–æ —Ñ–æ–ª–±—ç–∫ –Ω–∏–∂–µ
                # –§–æ–ª–±—ç–∫: –æ—Ç–ø—Ä–∞–≤–∏–º –∫–∞–∫ –¥–æ–∫—É–º–µ–Ω—Ç —Å –∏—Å—Ö–æ–¥–Ω—ã–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ–º
                try:
                    ext = '.jpg'
                    m = re.search(r"\.([a-z0-9]{3,4})(?:\?|$)", url.lower())
                    if m:
                        ext = '.' + m.group(1)
                except Exception:
                    ext = '.jpg'
                photo_data.seek(0)
                c = BytesIO(photo_data.read()); c.seek(0)
                doc_fallbacks.append((c, f"photo_{i}{ext}"))

        if loading_msg:
            try:
                await loading_msg.delete()
            except Exception:
                pass

        if len(media) == 1:
            await message.reply_photo(media[0].media, reply_markup=get_main_menu())
            for buf, fname in doc_fallbacks:
                buf.seek(0)
                await message.reply_document(InputFile(buf, filename=fname))
            return

        if 2 <= len(media) <= 10:
            await message.reply_media_group(media)
            for buf, fname in doc_fallbacks:
                buf.seek(0)
                await message.reply_document(InputFile(buf, filename=fname))
            return

        # –ë–∞—Ç—á–∏
        for start in range(0, len(media), 10):
            batch = media[start:start+10]
            try:
                await message.reply_media_group(batch)
                await asyncio.sleep(0.4)
            except Exception as e:
                logging.error(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –±–∞—Ç—á–∞ {(start//10)+1}: {e}")
        for buf, fname in doc_fallbacks:
            buf.seek(0)
            await message.reply_document(InputFile(buf, filename=fname))
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ process_media_urls: {e}")

# –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö —Å—Å—ã–ª–æ–∫ –Ω–∞ –º–µ–¥–∏–∞ –∏–∑ HTML
async def extract_potential_urls(url: str) -> list:
    global request_count
    request_count += 1
    try:
        # 1) –ë—ã—Å—Ç—Ä—ã–π HTTP-–ø–∞—Ä—Å–∏–Ω–≥ –±–µ–∑ Playwright: –≤—ã—Ç—è–Ω—É—Ç—å –≤—Å–µ realty-URL –∏–∑ HTML/—Å–∫—Ä–∏–ø—Ç–æ–≤
        try:
            async with aiohttp.ClientSession() as s:
                async with s.get(url, timeout=20) as r:
                    html_fast = await r.text(errors='ignore')
            # –†–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞ \u002F
            html_fast_unesc = html_fast.replace('\\u002F', '/')
            # –ò–∑–≤–ª–µ–∫–∞–µ–º id –æ–±—ä–µ–∫—Ç–∞ –∏–∑ URL
            _m = re.search(r"/flats/(\d+)/", url)
            obj_id = _m.group(1) if _m else None
            candidates = []
            # –®–∞–±–ª–æ–Ω—ã CDN
            patterns = [
                r"https?://(?:api\.easybase\.com\.ua|easybase\.b-cdn\.net)[^\s'\"<>]*/realty/(\d+)[^\s'\"<>]*\.(?:webp|jpg|jpeg|png|bmp)",
                r"https?://easybase\.b-cdn\.net/prod/media/realty/(\d+)[^\s'\"<>]*\.(?:webp|jpg|jpeg|png|bmp)"
            ]
            for pat in patterns:
                for m in re.findall(pat, html_fast_unesc, flags=re.IGNORECASE):
                    pass  # –Ω–∞–º –Ω—É–∂–µ–Ω —Ç–æ–ª—å–∫–æ id –≤ –≥—Ä—É–ø–ø–µ, –æ—Å–Ω–æ–≤–Ω—É—é —Å—Å—ã–ª–∫—É –≤–æ–∑—å–º—ë–º –≤—Ç–æ—Ä—ã–º –ø—Ä–æ—Ö–æ–¥–æ–º
            # –í—Ç–æ—Ä–æ–π –ø—Ä–æ—Ö–æ–¥: –ø—Ä–æ—Å—Ç–æ —Å–æ–±—Ä–∞—Ç—å –≤—Å–µ —Å—Å—ã–ª–∫–∏ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            for m in re.findall(r"https?://[^\s'\"<>]+\.(?:webp|jpg|jpeg|png|bmp)", html_fast_unesc, flags=re.IGNORECASE):
                lm = m.lower()
                if any(x in lm for x in ['.svg', 'favicon.ico', '/avatar/']):
                    continue
                if ('/realty/' in lm) and (('easybase.b-cdn.net' in lm) or ('api.easybase.com.ua' in lm)):
                    if (not obj_id) or (f"/{obj_id}/" in lm):
                        candidates.append(m)
            candidates = list(dict.fromkeys(candidates))
            if len(candidates) >= 6:  # –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è —Ä–∞–Ω–Ω–µ–≥–æ –≤–æ–∑–≤—Ä–∞—Ç–∞
                return candidates
        except Exception:
            pass

        async with async_playwright() as p:
            browser = await p.chromium.launch(headless=True)
            page = await browser.new_page()

            # –ö–æ–ª–ª–µ–∫—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏–∑ —Å–µ—Ç–µ–≤—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤
            network_image_urls = []

            async def on_response(response):
                try:
                    resp_url = response.url
                    ctype = (response.headers.get('content-type') or '').lower()
                    if ('image/' in ctype) or resp_url.lower().endswith(('.jpg', '.jpeg', '.png', '.gif', '.webp', '.bmp')):
                        # –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä, —á—Ç–æ–±—ã –æ—Ç—Å–µ—á—å –∏–∫–æ–Ω–∫–∏
                        clen = int(response.headers.get('content-length', '0'))
                        if clen == 0:
                            # –µ—Å–ª–∏ –Ω–µ—Ç content-length, –≤—Å—ë —Ä–∞–≤–Ω–æ –¥–æ–±–∞–≤–∏–º
                            clen = 1
                        if clen >= 2048:  # >=2KB ‚Äì –∑–∞—Ö–≤–∞—Ç—ã–≤–∞–µ–º –∏ –Ω–µ–±–æ–ª—å—à–∏–µ –ø—Ä–µ–≤—å—é
                            network_image_urls.append(resp_url)
                except Exception:
                    pass

            page.on('response', on_response)
            
            # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Ç–∞–π–º–∞—É—Ç–∞ –∏ –æ–∂–∏–¥–∞–Ω–∏–µ –∑–∞–≥—Ä—É–∑–∫–∏ (–º—è–≥—á–µ: domcontentloaded)
            try:
                await page.goto(url, timeout=30000, wait_until="domcontentloaded")
            except Exception:
                # –î–∞–∂–µ –µ—Å–ª–∏ –Ω–∞–≤–∏–≥–∞—Ü–∏—è —Å —Ç–∞–π–º–∞—É—Ç–æ–º, –ø—Ä–æ–¥–æ–ª–∂–∏–º –ø–æ–ø—ã—Ç–∫—É —Å–æ–±—Ä–∞—Ç—å —Ç–æ, —á—Ç–æ –µ—Å—Ç—å
                pass

            # –ë—ã—Å—Ç—Ä—ã–π –ø—É—Ç—å: –ø—Ä–æ–±—É–µ–º —Å—Ä–∞–∑—É –¥–æ—Å—Ç–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ Nuxt –∏ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ —Å–ª–∞–π–¥–µ—Ä–∞, –∏ –µ—Å–ª–∏ –∏—Ö –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Å—Ä–∞–∑—É
            try:
                early_nuxt = await page.evaluate('''() => {
                    try {
                        const nuxt = window.__NUXT__;
                        const arr = nuxt && nuxt.data && nuxt.data[0] && nuxt.data[0].shareObject && Array.isArray(nuxt.data[0].shareObject.images)
                            ? nuxt.data[0].shareObject.images.map(x => x && x.img_obj).filter(Boolean)
                            : [];
                        return arr;
                    } catch { return []; }
                }''')
            except Exception:
                early_nuxt = []

            try:
                early_dom = await page.evaluate('''() => {
                    const urls = new Set();
                    const add = u => { if (u) urls.add(String(u)); };
                    document.querySelectorAll('.image-carousel__slider-main-wrap .swiper-slide a.image-carousel__main-img').forEach(a => {
                        add(a.getAttribute('data-src'));
                        const img = a.querySelector('img');
                        if (img) add(img.getAttribute('src'));
                    });
                    return Array.from(urls);
                }''')
            except Exception:
                early_dom = []

            try:
                # –§–∏–ª—å—Ç—Ä—É–µ–º –Ω–∞ –ª–µ—Ç—É —Ç–æ–ª—å–∫–æ realty-URL –Ω–∞ CDN
                def _is_target(u: str) -> bool:
                    lu = u.lower()
                    return ('easybase.b-cdn.net' in lu) and ('/realty/' in lu) and lu.endswith(('.jpg','.jpeg','.png','.webp','.bmp','.gif'))
                early_urls = []
                seen_e = set()
                for u in list(early_nuxt) + list(early_dom):
                    if not u:
                        continue
                    uu = u.strip()
                    if uu.startswith('//'):
                        uu = 'https:' + uu
                    if uu not in seen_e and _is_target(uu):
                        seen_e.add(uu)
                        early_urls.append(uu)
                if len(early_urls) >= 12:
                    await browser.close()
                    return early_urls
            except Exception:
                pass
            # –ü—Ä–æ–∫—Ä—É—Ç–∫–∞ –¥–ª—è –ø–æ–¥–≥—Ä—É–∑–∫–∏ –ª–µ–Ω–∏–≤—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
            try:
                await page.evaluate('''async () => {
                    await new Promise((resolve) => {
                        let totalHeight = 0;
                        const distance = 400;
                        const timer = setInterval(() => {
                            const scrollHeight = document.body.scrollHeight;
                            window.scrollBy(0, distance);
                            totalHeight += distance;
                            if (totalHeight >= scrollHeight || totalHeight > 12000) {
                                clearInterval(timer);
                                resolve();
                            }
                        }, 120);
                    });
                }''')
            except Exception:
                pass
            await page.wait_for_timeout(3000)  # –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –ø–æ—Å–ª–µ –ø—Ä–æ–∫—Ä—É—Ç–∫–∏
            
            # –ü–æ–ª—É—á–∞–µ–º HTML –ø–æ—Å–ª–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è JavaScript
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ —Å–æ–±–∏—Ä–∞–µ–º —Å—Å—ã–ª–∫–∏ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–∞–ø—Ä—è–º—É—é –∏–∑ DOM —á–µ—Ä–µ–∑ JS
            try:
                dom_urls = await page.evaluate(r'''() => {
                    const urls = new Set();
                    const add = (u) => {
                        if (!u) return;
                        u = String(u).trim();
                        if (u.startsWith('//')) u = 'https:' + u;
                        urls.add(u);
                    };
                    // –í—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ –∏—Ö srcset
                    document.querySelectorAll('img').forEach(img => {
                        add(img.getAttribute('src'));
                        add(img.getAttribute('data-src'));
                        add(img.getAttribute('data-original'));
                        add(img.getAttribute('data-lazy'));
                        add(img.getAttribute('data-image'));
                        add(img.getAttribute('data-src-large'));
                        const sets = [img.getAttribute('srcset'), img.getAttribute('data-srcset')].filter(Boolean);
                        sets.forEach(ss => {
                            const first = String(ss).split(',')[0].trim().split(' ')[0];
                            add(first);
                        });
                    });
                    // –°—Å—ã–ª–∫–∏, —É–∫–∞–∑—ã–≤–∞—é—â–∏–µ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                    document.querySelectorAll('a').forEach(a => {
                        const href = a.getAttribute('href') || '';
                        const ds = a.getAttribute('data-src') || '';
                        if (/(\.jpg|\.jpeg|\.png|\.webp|\.gif|\.bmp)(\?|$)/i.test(href)) {
                            add(href);
                        }
                        if (/(\.jpg|\.jpeg|\.png|\.webp|\.gif|\.bmp)(\?|$)/i.test(ds)) {
                            add(ds);
                        }
                    });
                    // –§–æ–Ω–æ–≤—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                    document.querySelectorAll('[style*="background"]').forEach(el => {
                        try {
                            const bg = getComputedStyle(el).backgroundImage;
                            if (bg && bg.includes('url(')) {
                                const matches = bg.match(/url\(("|')?(.*?)\1\)/g) || [];
                                matches.forEach(m => {
                                    const u = m.replace(/^url\(("|')?/, '').replace(/\1?\)$/, '');
                                    add(u);
                                });
                            }
                        } catch {}
                    });
                    // –ü—Ä–æ—Ö–æ–¥ –ø–æ –≤—Å–µ–º –∞—Ç—Ä–∏–±—É—Ç–∞–º –≤—Å–µ—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤: –∏—â–µ–º CDN –∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
                    const reImg = /(https?:\/\/[^\s'"<>]+\.(?:jpg|jpeg|png|webp|gif|bmp))/ig;
                    const reCdn = /(https?:\/\/[^\s'"<>]*easybase\.b-cdn\.net[^\s'"<>]*)/ig;
                    document.querySelectorAll('*').forEach(el => {
                        for (const attr of el.getAttributeNames ? el.getAttributeNames() : []) {
                            const val = el.getAttribute(attr) || '';
                            let m;
                            while ((m = reImg.exec(val)) !== null) add(m[1]);
                            while ((m = reCdn.exec(val)) !== null) add(m[1]);
                        }
                    });
                    return Array.from(urls);
                }''')
            except Exception:
                dom_urls = []

            html_content = await page.content()
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –¥–æ—Å—Ç–∞—ë–º URL, –∑–∞–ø–∏—Å–∞–Ω–Ω—ã–µ —Å —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ —Å–ª–µ—à–∞–º–∏ (\u002F) –≤ —Å–∫—Ä–∏–ø—Ç–∞—Ö Nuxt
            escaped_urls = []
            try:
                esc_pattern = r"https:\\u002F\\u002F[^\s'\"<>]+\\.(?:jpg|jpeg|png|webp|gif|bmp)"
                for m in re.findall(esc_pattern, html_content, flags=re.IGNORECASE):
                    decoded = m.replace("\\u002F", "/")
                    escaped_urls.append(decoded)
            except Exception:
                pass
            
            # –ü—ã—Ç–∞–µ–º—Å—è –æ—Ç–∫—Ä—ã—Ç—å –º–æ–¥–∞–ª—å–Ω–æ–µ –æ–∫–Ω–æ –≥–∞–ª–µ—Ä–µ–∏ –∏ –ø—Ä–æ–π—Ç–∏—Å—å –ø–æ –≤—Å–µ–º —Ñ–æ—Ç–æ
            try:
                # –ö–ª–∏–∫–∏ –ø–æ –≤–æ–∑–º–æ–∂–Ω—ã–º —Ç—Ä–∏–≥–≥–µ—Ä–∞–º –≥–∞–ª–µ—Ä–µ–∏
                triggers = [
                    '[data-fancybox]','[data-gallery]','a.fancybox','a.lightbox','a[rel*="gallery"]',
                    '.gallery a','figure a','a.pswp__item','a.lg-item','a[href*=".jpg"], a[href*=".jpeg"], a[href*=".png"], a[href*=".webp"]'
                ]
                opened = False
                for sel in triggers:
                    els = await page.query_selector_all(sel)
                    if els:
                        try:
                            await els[0].click(timeout=1000)
                            opened = True
                            break
                        except Exception:
                            continue
                if not opened:
                    # –ü–æ–ø—Ä–æ–±—É–µ–º –∫–ª–∏–∫–Ω—É—Ç—å –ø–æ –ø–µ—Ä–≤–æ–π –∫—Ä—É–ø–Ω–æ–π –∫–∞—Ä—Ç–∏–Ω–∫–µ
                    hero = await page.query_selector('img')
                    if hero:
                        try:
                            await hero.click(timeout=1000)
                            opened = True
                        except Exception:
                            pass

                if opened:
                    await page.wait_for_timeout(500)
                    # –°–µ–ª–µ–∫—Ç–æ—Ä—ã —Ç–µ–∫—É—â–µ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö –≥–∞–ª–µ—Ä–µ—è—Ö
                    image_selectors = [
                        '.fancybox-image','.pswp__img','.lg-current img','.lg-item img',
                        '.lightgallery img:visible','.modal img','.swiper-slide-active img'
                    ]
                    next_selectors = [
                        '.fancybox-button--arrow_right','.pswp__button--arrow--right',
                        '.lg-next','.slick-next','.swiper-button-next','[aria-label="Next"]','button[title*="Next"]'
                    ]
                    seen = set()
                    for _ in range(40):
                        # —Å–æ–±—Ä–∞—Ç—å —Ç–µ–∫—É—â–µ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                        for sel in image_selectors:
                            imgs = await page.query_selector_all(sel)
                            for img in imgs:
                                try:
                                    src = await img.get_attribute('src')
                                    if not src:
                                        src = await img.get_attribute('data-src')
                                    if src and src not in seen:
                                        seen.add(src)
                                        # –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∏ –¥–æ–±–∞–≤–ª—è–µ–º
                                        u = urljoin(url, src)
                                        if u.startswith('//'):
                                            u = 'https:' + u
                                        dom_urls.append(u)
                                except Exception:
                                    pass
                        # –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –Ω–∞–∂–∞—Ç—å next
                        clicked = False
                        for nsel in next_selectors:
                            btn = await page.query_selector(nsel)
                            if btn:
                                try:
                                    await btn.click(timeout=800)
                                    clicked = True
                                    await page.wait_for_timeout(250)
                                    break
                                except Exception:
                                    continue
                        if not clicked:
                            break
            except Exception:
                pass

            # –ü—Ä–æ–±—É–µ–º –Ω–∞–∂–∞—Ç—å –≤–∫–ª–∞–¥–∫–∏/–∫–Ω–æ–ø–∫–∏ —Å —Ç–µ–∫—Å—Ç–æ–º –§–æ—Ç–æ/–§–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏/–ì–∞–ª–µ—Ä–µ—è –∏ –ø–µ—Ä–µ—Å–æ–±—Ä–∞—Ç—å —Å—Å—ã–ª–∫–∏
            try:
                await page.evaluate('''() => {
                    const texts = ['—Ñ–æ—Ç–æ', '—Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏', '–≥–∞–ª–µ—Ä–µ—è', 'photos', 'gallery'];
                    const clickIfMatch = (el) => {
                        try {
                            const t = (el.innerText || el.textContent || '').toLowerCase();
                            if (texts.some(x => t.includes(x))) el.click();
                        } catch {}
                    };
                    document.querySelectorAll('a,button,li,div,span').forEach(clickIfMatch);
                }''')
                await page.wait_for_timeout(500)
                # –°–æ–±–∏—Ä–∞–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤
                extra_dom_urls = await page.evaluate(r'''() => {
                    const urls = new Set();
                    const add = u => { if (u) urls.add(String(u)); };
                    const collect = root => {
                        root.querySelectorAll('img').forEach(img => {
                            add(img.getAttribute('src'));
                            add(img.getAttribute('data-src'));
                        });
                        root.querySelectorAll('[style*="background"]').forEach(el => {
                            try {
                                const bg = getComputedStyle(el).backgroundImage;
                                if (bg && bg.includes('url(')) {
                                    const m = bg.match(/url\(("|')?(.*?)\1\)/);
                                    if (m && m[2]) add(m[2]);
                                }
                            } catch {}
                        });
                    };
                    ['.swiper','.swiper-container','.gallery','.photos','.thumbnails'].forEach(sel => {
                        document.querySelectorAll(sel).forEach(collect);
                    });
                    return Array.from(urls);
                }''')
                for u in extra_dom_urls:
                    try:
                        # –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ –Ω–∏–∂–µ
                        pass
                    except Exception:
                        pass
                # –ø—Ä–æ—Å—Ç–æ –¥–æ–±–∞–≤–∏–º –∏—Ö —á—É—Ç—å –Ω–∏–∂–µ —á–µ—Ä–µ–∑ add_url –≤–º–µ—Å—Ç–µ —Å dom_urls
                dom_urls = (dom_urls or []) + (extra_dom_urls or [])
            except Exception:
                pass

            # –ü–æ–ø—ã—Ç–∫–∞ –∏–∑–≤–ª–µ—á—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ JSON –≤ script-—Ç–µ–≥–∞—Ö (–≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–µ –≥–∞–ª–µ—Ä–µ–∏)
            try:
                json_urls = await page.evaluate(r'''() => {
                    const out = [];
                    const push = u => { if (u) out.push(String(u)); };
                    const scripts = Array.from(document.querySelectorAll('script'));
                    for (const s of scripts) {
                        const t = s.textContent || '';
                        // –ò—â–µ–º –≤—Å–µ URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ —Ç–µ–∫—Å—Ç–µ —Å–∫—Ä–∏–ø—Ç–∞
                        const re = /(https?:\\/\\/[^\s'"<>]+\.(?:jpg|jpeg|png|webp|gif|bmp))/ig;
                        let m; while ((m = re.exec(t)) !== null) { push(m[1]); }
                        // –ü–æ–ø—Ä–æ–±—É–µ–º –ø—Ä–æ—Å—Ç–µ–π—à–∏–π JSON.parse, –µ—Å–ª–∏ –ø–æ—Ö–æ–∂–µ –Ω–∞ –º–∞—Å—Å–∏–≤
                        try {
                            const trimmed = t.trim();
                            if (trimmed.startsWith('[') && trimmed.endsWith(']')) {
                                const arr = JSON.parse(trimmed);
                                if (Array.isArray(arr)) {
                                    for (const v of arr) {
                                        if (typeof v === 'string' && /(\.jpg|\.jpeg|\.png|\.webp|\.gif|\.bmp)(\?|$)/i.test(v)) push(v);
                                        if (v && typeof v === 'object') {
                                            for (const k of Object.keys(v)) {
                                                const val = v[k];
                                                if (typeof val === 'string' && /(\.jpg|\.jpeg|\.png|\.webp|\.gif|\.bmp)(\?|$)/i.test(val)) push(val);
                                            }
                                        }
                                    }
                                }
                            }
                        } catch {}
                    }
                    return out;
                }''')
            except Exception:
                json_urls = []

            # –Ø–≤–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–∑ Nuxt: window.__NUXT__.data[0].shareObject.images[].img_obj
            try:
                nuxt_images = await page.evaluate('''() => {
                    try {
                        const nuxt = window.__NUXT__;
                        const arr = nuxt && nuxt.data && nuxt.data[0] && nuxt.data[0].shareObject && Array.isArray(nuxt.data[0].shareObject.images)
                            ? nuxt.data[0].shareObject.images.map(x => x && x.img_obj).filter(Boolean)
                            : [];
                        return arr;
                    } catch (e) { return []; }
                }''')
            except Exception:
                nuxt_images = []

            # –ó–∞–∫—Ä—ã–≤–∞–µ–º –±—Ä–∞—É–∑–µ—Ä
            await browser.close()
            
            # –ü–∞—Ä—Å–∏–º HTML
            soup = BeautifulSoup(html_content, 'html.parser')
            urls = []

            def add_url(u: str):
                if not u:
                    return
                u = u.strip()
                # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ URL
                u = urljoin(url, u)
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å—Ö–µ–º—ã —Ç–∏–ø–∞ //cdn
                if u.startswith('//'):
                    u = 'https:' + u
                if u.startswith(('http://', 'https://')):
                    urls.append(u)

            # <img src> –∏ data-src
            for img in soup.find_all('img'):
                add_url(img.get('src'))
                add_url(img.get('data-src'))
                # srcset / data-srcset: –±–µ—Ä—ë–º –ø–µ—Ä–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
                for attr in ('srcset', 'data-srcset'):
                    srcset = img.get(attr)
                    if srcset:
                        first = srcset.split(',')[0].strip().split(' ')[0]
                        add_url(first)

            # <picture><source srcset>
            for source in soup.find_all('source'):
                srcset = source.get('srcset')
                if srcset:
                    first = srcset.split(',')[0].strip().split(' ')[0]
                    add_url(first)

            # <noscript><img>
            for noscr in soup.find_all('noscript'):
                inner = BeautifulSoup(noscr.get_text() or '', 'html.parser')
                for img in inner.find_all('img'):
                    add_url(img.get('src'))
                    add_url(img.get('data-src'))

            # OpenGraph meta og:image
            for meta in soup.find_all('meta', property=lambda v: v in ('og:image', 'og:image:secure_url') if v else False):
                add_url(meta.get('content'))

            # link rel=image_src
            for link in soup.find_all('link', rel=lambda r: r and ('image_src' in r or 'icon' in r)):
                add_url(link.get('href'))

            # –î–æ–±–∞–≤–ª—è–µ–º URL, —Å–æ–±—Ä–∞–Ω–Ω—ã–µ –∏–∑ DOM
            try:
                for u in dom_urls:
                    add_url(u)
            except Exception:
                pass

            # –î–æ–±–∞–≤–ª—è–µ–º URL –∏–∑ —Å–∫—Ä–∏–ø—Ç–æ–≤
            try:
                for u in json_urls:
                    add_url(u)
            except Exception:
                pass

            # –î–æ–±–∞–≤–ª—è–µ–º URL –∏–∑ Nuxt
            try:
                for u in nuxt_images:
                    add_url(u)
            except Exception:
                pass
            # –î–æ–±–∞–≤–ª—è–µ–º —Ä–∞—Å—ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ URL –∏–∑ —Å–∫—Ä–∏–ø—Ç–æ–≤
            try:
                for u in escaped_urls:
                    add_url(u)
            except Exception:
                pass

            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ: —Å–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –ø—Ä—è–º—ã–µ —Å—Å—ã–ª–∫–∏ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ HTML —á–µ—Ä–µ–∑ regex
            try:
                img_url_pattern = r"https?://[^\s'\"<>]+\.(?:jpg|jpeg|png|webp|gif|bmp)"
                for m in re.findall(img_url_pattern, html_content, flags=re.IGNORECASE):
                    add_url(m)
            except Exception:
                pass

            # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å –∫–∞—Ä—Ç–∏–Ω–∫–∞–º–∏ –∏–∑ —Å–µ—Ç–∏
            for nu in network_image_urls:
                add_url(nu)

            # –£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –∏ –≤–æ–∑–≤—Ä–∞—Ç
            urls = list(dict.fromkeys(urls))
            return urls
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Å—Å—ã–ª–æ–∫: {str(e)}")
        return []

# –ü–∞—Ä—Å–∏–Ω–≥ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –Ω–∞–ø—Ä—è–º—É—é –∏–∑ HTML (–±–µ–∑ Playwright)
def parse_image_urls_from_html(html: str, base_url: str | None = None) -> list:
    try:
        soup = BeautifulSoup(html, 'html.parser')
        urls = []
        for img in soup.find_all('img'):
            src = img.get('src') or img.get('data-src')
            if not src:
                continue
            if base_url:
                full = urljoin(base_url, src)
            else:
                # –ï—Å–ª–∏ –Ω–µ—Ç base_url, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ –ø—É—Ç–∏
                if src.startswith('//'):
                    full = 'https:' + src
                elif src.startswith(('http://', 'https://')):
                    full = src
                else:
                    continue
            urls.append(full)
        # –£–Ω–∏–∫–∞–ª–∏–∑–∏—Ä—É–µ–º –∏ —Ñ–∏–ª—å—Ç—Ä—É–µ–º
        urls = list(set(urls))
        return [u for u in urls if u.startswith(('http://', 'https://'))]
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ HTML: {str(e)}")
        return []

# –ü–æ–ø—ã—Ç–∫–∞ –Ω–∞–π—Ç–∏ –º–µ–¥–∏–∞ —á–µ—Ä–µ–∑ Playwright
async def fetch_media_url(url: str) -> tuple:
    try:
        logging.info(f"–ù–∞—á–∏–Ω–∞–µ–º –ø–æ–∏—Å–∫ –º–µ–¥–∏–∞ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ: {url}")
        # –°–ø–µ—Ü–∏–∞–ª—å–Ω–æ–µ –ø—Ä–∞–≤–∏–ª–æ: –Ω–∞ easyhata.site –≤–∏–¥–µ–æ –Ω–µ –∏—â–µ–º –≤–æ–≤—Å–µ
        try:
            _host = urlparse(url).netloc.lower()
            if 'easyhata.site' in _host:
                return "", ""
        except Exception:
            pass
        
        # –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏ –¥–ª—è –≤—Å–µ—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'en-US,en;q=0.5',
            'Referer': 'https://www.google.com/',
            'DNT': '1',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
            'Cache-Control': 'max-age=0'
        }
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º Playwright
        async with async_playwright() as p:
            # –ó–∞–ø—É—Å–∫–∞–µ–º –±—Ä–∞—É–∑–µ—Ä —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
            browser = await p.chromium.launch(
                headless=True,
                args=[
                    '--disable-blink-features=AutomationControlled',
                    '--no-sandbox',
                    '--disable-setuid-sandbox',
                    '--disable-dev-shm-usage',
                    '--disable-accelerated-2d-canvas',
                    '--no-first-run',
                    '--no-zygote',
                    '--single-process',
                    '--disable-gpu'
                ]
            )
            
            # –°–æ–∑–¥–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
            context = await browser.new_context(
                user_agent=headers['User-Agent'],
                viewport={'width': 1920, 'height': 1080},
                locale='en-US',
                timezone_id='America/New_York',
                permissions=['geolocation']
            )
            
            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏
            await context.set_extra_http_headers({
                'Accept-Language': headers['Accept-Language'],
                'Referer': headers['Referer'],
                'DNT': headers['DNT']
            })
            
            # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É
            page = await context.new_page()
            
            # –í–∫–ª—é—á–∞–µ–º –ø–µ—Ä–µ—Ö–≤–∞—Ç —Å–µ—Ç–µ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
            video_urls = []
            
            async def handle_response(response):
                try:
                    url = response.url.lower()
                    content_type = (response.headers.get('content-type') or '').lower()
                    
                    # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –Ω–µ–Ω—É–∂–Ω—ã–µ —Ç–∏–ø—ã –∑–∞–ø—Ä–æ—Å–æ–≤
                    if any(x in url for x in ['.css', '.js', '.png', '.jpg', '.jpeg', '.gif', '.webp', '.svg']):
                        return
                        
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –≤–∏–¥–µ–æ-–∫–æ–Ω—Ç–µ–Ω—Ç
                    is_video = ('video/' in content_type or 
                              any(ext in url for ext in ['.mp4', '.webm', '.mov', '.m3u8', 'video/']))
                    
                    if is_video and url not in video_urls:
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä –∫–æ–Ω—Ç–µ–Ω—Ç–∞
                        content_length = int(response.headers.get('content-length', '0'))
                        if content_length > 100000:  # –ë–æ–ª—å—à–µ 100 –ö–ë
                            video_urls.append(url)
                            logging.info(f"–ù–∞–π–¥–µ–Ω–æ –≤–∏–¥–µ–æ: {url} (—Ç–∏–ø: {content_type}, —Ä–∞–∑–º–µ—Ä: {content_length} –±–∞–π—Ç)")
                            
                except Exception as e:
                    logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –æ—Ç–≤–µ—Ç–∞: {str(e)}")
            
            # –ü–æ–¥–ø–∏—Å—ã–≤–∞–µ–º—Å—è –Ω–∞ —Å–æ–±—ã—Ç–∏—è –æ—Ç–≤–µ—Ç–æ–≤
            page.on("response", handle_response)
            
            try:
                # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ –¥–ª—è –æ–±—Ö–æ–¥–∞ –∑–∞—â–∏—Ç—ã
                await page.goto(
                    url,
                    timeout=60000,
                    wait_until="domcontentloaded",
                    referer=headers['Referer']
                )
                
                # –ñ–¥–µ–º –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
                await page.wait_for_load_state('networkidle', timeout=30000)
                
                # –ü—Ä–æ–∫—Ä—É—á–∏–≤–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É –≤–Ω–∏–∑ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –ª–µ–Ω–∏–≤–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
                await page.evaluate('''async () => {
                    await new Promise((resolve) => {
                        let totalHeight = 0;
                        const distance = 100;
                        const timer = setInterval(() => {
                            const scrollHeight = document.body.scrollHeight;
                            window.scrollBy(0, distance);
                            totalHeight += distance;
                            if (totalHeight >= scrollHeight || totalHeight > 2000) {
                                clearInterval(timer);
                                resolve();
                            }
                        }, 100);
                    });
                }''')
                
                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ –æ–∂–∏–¥–∞–Ω–∏–µ –ø–æ—Å–ª–µ –ø—Ä–æ–∫—Ä—É—Ç–∫–∏
                await page.wait_for_timeout(3000)
                
                # –ò—â–µ–º –≤–∏–¥–µ–æ-—ç–ª–µ–º–µ–Ω—Ç—ã –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ
                video_elements = await page.query_selector_all('video')
                for video in video_elements:
                    try:
                        # –ü—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å src
                        src = await video.get_attribute('src')
                        if src and src.startswith(('http://', 'https://')) and src not in video_urls:
                            video_urls.append(src)
                            logging.info(f"–ù–∞–π–¥–µ–Ω–æ –≤–∏–¥–µ–æ –≤ —Ç–µ–≥–µ video: {src}")
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º source –≤–Ω—É—Ç—Ä–∏ video
                        sources = await video.query_selector_all('source')
                        for source in sources:
                            src = await source.get_attribute('src')
                            if src and src.startswith(('http://', 'https://')) and src not in video_urls:
                                video_urls.append(src)
                                logging.info(f"–ù–∞–π–¥–µ–Ω–æ –≤–∏–¥–µ–æ –≤ —Ç–µ–≥–µ source: {src}")
                                
                    except Exception as e:
                        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∏–¥–µ–æ-—ç–ª–µ–º–µ–Ω—Ç–∞: {str(e)}")
                
                # –ï—Å–ª–∏ –≤–∏–¥–µ–æ –Ω–µ –Ω–∞—à–ª–∏, –∏—â–µ–º iframe —Å –≤–∏–¥–µ–æ
                if not video_urls:
                    iframes = await page.query_selector_all('iframe')
                    for iframe in iframes:
                        try:
                            src = await iframe.get_attribute('src')
                            if src and any(x in src.lower() for x in ['youtube', 'vimeo', 'dailymotion', 'player']):
                                video_urls.append(src)
                                logging.info(f"–ù–∞–π–¥–µ–Ω–æ –≤–∏–¥–µ–æ –≤ iframe: {src}")
                        except:
                            continue
                
                # –ï—Å–ª–∏ –≤–∏–¥–µ–æ –Ω–∞—à–ª–∏, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–µ—Ä–≤–æ–µ
                if video_urls:
                    cand = video_urls[0]
                    if not cand.lower().endswith(('.jpg', '.jpeg', '.png', '.gif', '.webp', '.bmp')):
                        return cand, 'video'
                
                # –ï—Å–ª–∏ –≤–∏–¥–µ–æ –Ω–µ –Ω–∞—à–ª–∏, –∏—â–µ–º –≤ JSON-LD —Ä–∞–∑–º–µ—Ç–∫–µ
                try:
                    json_ld = await page.evaluate('''() => {
                        const scripts = document.querySelectorAll('script[type="application/ld+json"]');
                        for (const script of scripts) {
                            try {
                                return JSON.parse(script.textContent);
                            } catch (e) {}
                        }
                        return null;
                    }''')
                    
                    if json_ld and isinstance(json_ld, dict):
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–ª–∏—á–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ –ø—É—Ç–∏ –∫ –≤–∏–¥–µ–æ –≤ JSON-LD
                        for key in ['contentUrl', 'embedUrl', 'url', 'video']:
                            if key in json_ld and isinstance(json_ld[key], str) and json_ld[key].startswith(('http://', 'https://')):
                                return json_ld[key], 'video'
                except Exception as e:
                    logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ JSON-LD: {str(e)}")
                
                # –ò—â–µ–º –≤–∏–¥–µ–æ –≤ iframe
                frames = page.frames
                for frame in frames:
                    try:
                        video_elements = await frame.query_selector_all('video')
                        for video in video_elements:
                            src = await video.get_attribute('src')
                            if src and src.startswith(('http://', 'https://')) and src not in video_urls:
                                video_urls.append(src)
                    except:
                        continue
                
                # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ –≤–∏–¥–µ–æ, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–µ—Ä–≤–æ–µ (–∏—Å–∫–ª—é–∞–µ–º —Å—Å—ã–ª–∫–∏ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è)
                if video_urls:
                    cand2 = video_urls[0]
                    if not cand2.lower().endswith(('.jpg', '.jpeg', '.png', '.gif', '.webp', '.bmp')):
                        return cand2, 'video'
                
                # –ï—Å–ª–∏ –≤–∏–¥–µ–æ –Ω–µ –Ω–∞—à–ª–∏, –∏—â–µ–º —Ç–µ–≥–∏ video –∏ source
                video_elements = await page.query_selector_all('video')
                for video in video_elements:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞—Ç—Ä–∏–±—É—Ç src
                    src = await video.get_attribute('src')
                    if src and src.startswith(('http://', 'https://')):
                        if not src.lower().endswith(('.jpg', '.jpeg', '.png', '.gif', '.webp', '.bmp')):
                            return src, 'video'
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º source –≤–Ω—É—Ç—Ä–∏ video
                    source_elements = await video.query_selector_all('source')
                    for source in source_elements:
                        src = await source.get_attribute('src')
                        if src and src.startswith(('http://', 'https://')):
                            if not src.lower().endswith(('.jpg', '.jpeg', '.png', '.gif', '.webp', '.bmp')):
                                return src, 'video'
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º iframe —Å YouTube, Vimeo –∏ –¥—Ä—É–≥–∏–º–∏ –≤—Å—Ç—Ä–∞–∏–≤–∞–µ–º—ã–º–∏ –ø–ª–µ–µ—Ä–∞–º–∏
                iframes = await page.query_selector_all('iframe')
                for iframe in iframes:
                    src = await iframe.get_attribute('src')
                    if src and any(domain in src for domain in ['youtube.com', 'youtu.be', 'vimeo.com', 'dailymotion.com']):
                        return src, 'video'
                
                # –ï—Å–ª–∏ –≤–∏–¥–µ–æ –Ω–µ –Ω–∞—à–ª–∏, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–µ—Ä–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                img_elements = await page.query_selector_all('img')
                for img in img_elements:
                    src = await img.get_attribute('src') or await img.get_attribute('data-src')
                    if src and src.startswith(('http://', 'https://')):
                        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –º–∞–ª–µ–Ω—å–∫–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–∏–∫–æ–Ω–∫–∏, –∞–≤–∞—Ç–∞—Ä—ã –∏ —Ç.–¥.)
                        width = await img.get_attribute('width')
                        height = await img.get_attribute('height')
                        if width and height and int(width) > 100 and int(height) > 100:
                            return src, 'photo'
                
                return "", ""
                
            except Exception as e:
                logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {url}: {str(e)}")
                return "", str(e)
                
            finally:
                # –ó–∞–∫—Ä—ã–≤–∞–µ–º –±—Ä–∞—É–∑–µ—Ä
                if 'context' in locals():
                    await context.close()
                if 'browser' in locals():
                    await browser.close()
                    
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ Playwright –¥–ª—è {url}: {str(e)}", exc_info=True)
        if 'browser' in locals():
            try:
                await browser.close()
            except:
                pass
        return "", ""
async def download_media(url: str, session: aiohttp.ClientSession, headers: dict = None) -> tuple:
    try:
        logging.info(f"–ù–∞—á–∏–Ω–∞–µ–º —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ: {url}")

        # –ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        if headers is None:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
                'Accept': '*/*',
                'Accept-Language': 'en-US,en;q=0.9'
            }

        # –ï—Å–ª–∏ —ç—Ç–æ –ø–æ—Ö–æ–∂–µ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º image-–æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏
        lower_url = url.lower()
        if lower_url.endswith(('.jpg', '.jpeg', '.png', '.gif', '.webp', '.bmp')):
            headers = {
                'User-Agent': headers.get('User-Agent', 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'),
                'Accept': 'image/avif,image/webp,image/apng,image/*,*/*;q=0.8',
                'Accept-Language': headers.get('Accept-Language', 'en-US,en;q=0.9')
            }
            # –ê–≤—Ç–æ-Referer –Ω–∞ –¥–æ–º–µ–Ω —Ä–µ—Å—É—Ä—Å–∞
            try:
                parsed = urlparse(url)
                if parsed.scheme and parsed.netloc:
                    headers['Referer'] = f"{parsed.scheme}://{parsed.netloc}/"
            except Exception:
                pass

        async with session.get(url, headers=headers, timeout=30) as response:
            if response.status != 200:
                error_text = await response.text()
                logging.error(f"–û—à–∏–±–∫–∞ HTTP {response.status} –¥–ª—è URL: {url}\n{error_text[:500]}")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Ç—Ä–µ–±—É–µ—Ç –ª–∏ —Å–∞–π—Ç –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏
                if response.status == 401 or 'login' in error_text.lower():
                    return None, "–î–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ —ç—Ç–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ —Ç—Ä–µ–±—É–µ—Ç—Å—è –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –Ω–∞ —Å–∞–π—Ç–µ üö´"
                elif response.status == 403:
                    return None, "–î–æ—Å—Ç—É–ø –∫ —ç—Ç–æ–º—É –∫–æ–Ω—Ç–µ–Ω—Ç—É –∑–∞–ø—Ä–µ—â–µ–Ω (–æ—à–∏–±–∫–∞ 403) üîí"
                elif response.status == 404:
                    return None, "–ö–æ–Ω—Ç–µ–Ω—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω (–æ—à–∏–±–∫–∞ 404) üîç"
                else:
                    return None, f"–û—à–∏–±–∫–∞ {response.status} –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ üö´"
        
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–∞ —Ñ–∞–π–ª–∞
            content_length = response.content_length or 0
            if content_length > MAX_FILE_SIZE:
                size_mb = content_length / (1024 * 1024)
                logging.error(f"–§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π: {size_mb:.2f} –ú–ë")
                return None, f"–§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π ({size_mb:.2f} –ú–ë). Telegram –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ—Ç —Ä–∞–∑–º–µ—Ä –¥–æ 50 –ú–ë üö´"
        
            # –°–∫–∞—á–∏–≤–∞–Ω–∏–µ —Å –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
            content = bytearray()
            async for chunk in response.content.iter_chunked(8192):
                content.extend(chunk)
                if len(content) > MAX_FILE_SIZE:
                    logging.error(f"–§–∞–π–ª –ø—Ä–µ–≤—ã—Å–∏–ª –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ: {len(content) / (1024*1024):.2f} –ú–ë")
                    return None, "–§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ üö´"
        
            logging.info(f"–£—Å–ø–µ—à–Ω–æ —Å–∫–∞—á–∞–Ω —Ñ–∞–π–ª —Ä–∞–∑–º–µ—Ä–æ–º: {len(content) / 1024:.2f} –ö–ë")
            return BytesIO(content), None
            
    except asyncio.TimeoutError:
        logging.error(f"–¢–∞–π–º–∞—É—Ç –ø—Ä–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–∏: {url}")
        return None, "–ü—Ä–µ–≤—ã—à–µ–Ω–æ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –ø—Ä–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–∏ üö´"
    except aiohttp.ClientError as e:
        logging.error(f"–û—à–∏–±–∫–∞ —Å–µ—Ç–∏ –ø—Ä–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–∏ {url}: {str(e)}")
        return None, f"–û—à–∏–±–∫–∞ —Å–µ—Ç–∏: {str(e)} üö´"
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è {url}: {str(e)}", exc_info=True)
        return None, f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –∫–æ–Ω—Ç–µ–Ω—Ç–∞: {str(e)} üö´"

# –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ –º–µ–¥–∏–∞ –ø–æ URL
def get_media_type(url: str):
    url_lower = url.lower()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ –≤–∏–¥–µ–æ—Ö–æ—Å—Ç–∏–Ω–≥–∏
    video_domains = [
        'youtube.com', 'youtu.be', 'vimeo.com', 'dailymotion.com', 'twitch.tv',
        'tiktok.com', 'instagram.com/reel', 'facebook.com/watch', 'youtube.com/shorts'
    ]
    
    if any(domain in url_lower for domain in video_domains):
        return 'video'
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è —Ñ–∞–π–ª–æ–≤
    if any(url_lower.endswith(ext) for ext in IMAGE_EXTENSIONS):
        return 'photo'
    elif any(url_lower.endswith(ext) for ext in VIDEO_EXTENSIONS):
        return 'video'
        
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º MIME-—Ç–∏–ø—ã –≤ URL
    if 'video/' in url_lower or 'stream/' in url_lower or 'media/video' in url_lower:
        return 'video'
        
    return 'unknown'

# –ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: —è–≤–ª—è–µ—Ç—Å—è –ª–∏ URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º –ø–æ –∑–∞–≥–æ–ª–æ–≤–∫—É Content-Type
async def is_image_url(session: aiohttp.ClientSession, url: str) -> bool:
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'image/avif,image/webp,image/apng,image/*,*/*;q=0.8',
            'Accept-Language': 'en-US,en;q=0.9'
        }
        # –ü—Ä–æ–±—É–µ–º HEAD –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ —Ç—Ä–∞—Ñ–∏–∫–∞
        try:
            async with session.head(url, headers=headers, allow_redirects=True, timeout=15) as resp:
                ctype = (resp.headers.get('Content-Type') or '').lower()
                return ctype.startswith('image/')
        except aiohttp.ClientResponseError as e:
            if e.status not in (400, 405):
                raise
        except Exception:
            # –§–æ–ª–ª–±—ç–∫ –Ω–∞ GET, –µ—Å–ª–∏ HEAD –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è
            pass

        async with session.get(url, headers=headers, allow_redirects=True, timeout=15) as resp:
            ctype = (resp.headers.get('Content-Type') or '').lower()
            return ctype.startswith('image/')
    except Exception:
        return False

# –ê–Ω–∏–º–∞—Ü–∏—è –∑–∞–≥—Ä—É–∑–∫–∏
async def show_loading_animation(message: Message, media_type: str = '–º–µ–¥–∏–∞'):
    try:
        loading_msg = await message.reply(f"–ó–∞–≥—Ä—É–∑–∫–∞ {media_type}... {LOADING_EMOJIS[0]}", parse_mode='Markdown')
        if len(LOADING_EMOJIS) > 1:
            for emoji in LOADING_EMOJIS[1:]:
                try:
                    await asyncio.sleep(0.5)
                    await loading_msg.edit_text(f"–ó–∞–≥—Ä—É–∑–∫–∞ {media_type}... {emoji}", parse_mode='Markdown')
                except Exception as e:
                    logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –∞–Ω–∏–º–∞—Ü–∏–∏: {str(e)}")
                    break
        return loading_msg
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∞–Ω–∏–º–∞—Ü–∏–∏ –∑–∞–≥—Ä—É–∑–∫–∏: {str(e)}")
        return None

# –ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é
def get_main_menu():
    keyboard = InlineKeyboardMarkup(inline_keyboard=[
        [InlineKeyboardButton("–û—Ç–ø—Ä–∞–≤–∏—Ç—å HTML-–∫–æ–¥ üìÑ", callback_data="send_html")],
        [InlineKeyboardButton("–ü–æ–¥–¥–µ—Ä–∂–∫–∞ üåü", callback_data="support")]
    ])
    return keyboard

# –ö–æ–º–∞–Ω–¥–∞ /start
async def send_welcome(message: Message):
    user_id = message.from_user.id
    update_user_activity(user_id)
    await message.reply(
        "–î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å –≤ –±–æ—Ç –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –≤–∏–¥–µ–æ! üìπ\n\n"
        "–û—Ç–ø—Ä–∞–≤—å—Ç–µ HTML-–∫–æ–¥ —Å—Ç—Ä–∞–Ω–∏—Ü—ã, –∏ —è –ø–æ–ø—ã—Ç–∞—é—Å—å –Ω–∞–π—Ç–∏ –∏ —Å–∫–∞—á–∞—Ç—å –≤–∏–¥–µ–æ.\n"
        "‚ö†Ô∏è Telegram –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ—Ç —Ä–∞–∑–º–µ—Ä —Å–∫–∞—á–∏–≤–∞–µ–º—ã—Ö —Ñ–∞–π–ª–æ–≤ –¥–æ 50 –ú–ë.\n"
        "–†–∞–±–æ—Ç–∞–µ—Ç —Å —Ç–µ–≥–∞–º–∏ <video>, <iframe> –∏–ª–∏ —Å—Å—ã–ª–∫–∞–º–∏ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã.\n\n"
        "–í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ:",
        reply_markup=get_main_menu()
    )

# –ö–æ–º–∞–Ω–¥–∞ /support
async def send_support(message: Message):
    user_id = message.from_user.id
    update_user_activity(user_id)
    await message.reply(
        "üåü *–ü–æ–¥–¥–µ—Ä–∂–∫–∞*\n\n"
        "–ï—Å–ª–∏ –±–æ—Ç –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –∏–ª–∏ —É –≤–∞—Å –µ—Å—Ç—å –≤–æ–ø—Ä–æ—Å—ã, –ø–∏—à–∏—Ç–µ: @makar2108 üì©\n"
        "‚ö†Ô∏è Telegram –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ—Ç —Ä–∞–∑–º–µ—Ä —Å–∫–∞—á–∏–≤–∞–µ–º—ã—Ö —Ñ–∞–π–ª–æ–≤ –¥–æ 50 –ú–ë.\n\n"
        "–ü–æ–¥–¥–µ—Ä–∂–∏—Ç–µ –ø—Ä–æ–µ–∫—Ç –¥–æ–±—Ä–æ–≤–æ–ª—å–Ω—ã–º –ø–æ–∂–µ—Ä—Ç–≤–æ–≤–∞–Ω–∏–µ–º:\n"
        "BEP-20 USDT: `0xc4b648A590A61F2F1d8b99f41248066533428471` üí∏",
        parse_mode='Markdown',
        reply_markup=get_main_menu()
    )

# –ö–æ–º–∞–Ω–¥–∞ /admin
async def admin_status(message: Message):
    user_id = message.from_user.id
    update_user_activity(user_id)
    if user_id != ADMIN_ID:
        await message.reply("–î–æ—Å—Ç—É–ø–Ω–æ —Ç–æ–ª—å–∫–æ –∞–¥–º–∏–Ω—É. üîê", reply_markup=get_main_menu())
        return
    await message.reply(
        "üîê *–ê–¥–º–∏–Ω-–ø–∞–Ω–µ–ª—å*\n\n"
        "–í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ:",
        parse_mode='Markdown',
        reply_markup=get_admin_menu()
    )

# –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π (URL –∏–ª–∏ HTML-–∫–æ–¥)
async def handle_html(message: Message):
    try:
        user_id = message.from_user.id
        update_user_activity(user_id)
        content = message.text.strip()
        
        logging.info(f"–ü–æ–ª—É—á–µ–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}: {content[:50]}...")
        
        # –°–æ–∑–¥–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –æ –∑–∞–≥—Ä—É–∑–∫–µ
        loading_msg = await show_loading_animation(message, "–∫–æ–Ω—Ç–µ–Ω—Ç–∞")
        if loading_msg is None:
            await message.reply("–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —Å–æ–æ–±—â–µ–Ω–∏—è –æ –∑–∞–≥—Ä—É–∑–∫–µ. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞.")
            return
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ URL
        is_url = content.startswith(('http://', 'https://'))
        
        if is_url:
            logging.info(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ URL: {content}")
            
            # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–æ –≤–∏–¥–µ–æ
            media_type = get_media_type(content)
            if media_type == 'video':
                await process_video_url(message, content, loading_msg)
                return
                
            # –ï—Å–ª–∏ —ç—Ç–æ –Ω–µ –≤–∏–¥–µ–æ, –∏—â–µ–º –º–µ–¥–∏–∞ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ
            if loading_msg is not None:
                try:
                    await loading_msg.edit_text("üîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –º–µ–¥–∏–∞...")
                except Exception:
                    pass
            
            # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –º–µ–¥–∏–∞ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ
            media_url, media_kind = await fetch_media_url(content)
            potential_urls = []
            if media_url and media_kind == 'video':
                await process_video_url(message, media_url, loading_msg)
                return
            if media_url and media_kind == 'photo':
                potential_urls.append(media_url)
            
            # –ò—â–µ–º –≤—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ –∏ –æ–±—ä–µ–¥–∏–Ω—è–µ–º
            if loading_msg is not None:
                try:
                    await loading_msg.edit_text("üîç –í–∏–¥–µ–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –∏—â—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è...")
                except Exception:
                    pass
            more_urls = await extract_potential_urls(content)
            if more_urls:
                # –û–±—ä–µ–¥–∏–Ω—è–µ–º –±–µ–∑ –¥—É–±–ª–µ–π, —Å–æ—Ö—Ä–∞–Ω—è—è –ø–æ—Ä—è–¥–æ–∫: —Å–Ω–∞—á–∞–ª–∞ –Ω–∞–π–¥–µ–Ω–Ω–æ–µ –æ—Å–Ω–æ–≤–Ω–æ–µ —Ñ–æ—Ç–æ, –∑–∞—Ç–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ
                seen = set(potential_urls)
                for u in more_urls:
                    if u not in seen:
                        potential_urls.append(u)
                        seen.add(u)
        else:
            logging.info("–û–±—Ä–∞–±–æ—Ç–∫–∞ HTML-–∫–æ–¥–∞ (–ª–æ–∫–∞–ª—å–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥)")
            potential_urls = parse_image_urls_from_html(content)
        
        # –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –¥–ª—è easyhata: –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ CDN realty –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞
        try:
            from urllib.parse import urlparse
            import re as _re
            parsed = urlparse(content)
            host = (parsed.netloc or '').lower()
            obj_id = None
            m = _re.search(r"/flats/(\d+)/", parsed.path or '')
            if m:
                obj_id = m.group(1)

            def is_target_url(u: str) -> bool:
                lu = (u or '').lower()
                if any(x in lu for x in ['.svg', 'favicon.ico']):
                    return False
                if 'avatar' in lu:
                    return False
                if (('easybase.b-cdn.net' in lu and '/realty/' in lu) or
                    ('api.easybase.com.ua' in lu and '/media/realty/' in lu)):
                    if obj_id and f"/{obj_id}/" in lu:
                        return True
                    # –µ—Å–ª–∏ id –Ω–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å, –≤—Å—ë —Ä–∞–≤–Ω–æ –¥–æ–ø—É—Å–∫–∞–µ–º realty
                    return True
                return False

            # –µ—Å–ª–∏ —ç—Ç–æ easyhata –∏ –Ω–∞—à–ª–∏ —Ü–µ–ª–µ–≤—ã–µ —Å—Å—ã–ª–∫–∏ ‚Äî —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ –∏—Ö
            if 'easyhata.site' in host:
                filtered = [u for u in potential_urls if is_target_url(u)]
                if len(filtered) >= 1:
                    potential_urls = filtered
        except Exception:
            pass

        logging.info(f"–ù–∞–π–¥–µ–Ω–æ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö URL: {len(potential_urls)}")
        
        if not potential_urls:
            if loading_msg is not None:
                try:
                    await loading_msg.delete()
                except Exception:
                    pass
            await message.reply(
                "–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏. üö´\n"
                "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å —Å—Å—ã–ª–∫–∏ –∏–ª–∏ HTML-–∫–æ–¥–∞.",
                reply_markup=get_main_menu()
            )
            return
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        photo_urls = []
        async with aiohttp.ClientSession() as session:
            for url in potential_urls:
                # –î–ª—è —Ü–µ–ª–µ–≤—ã—Ö CDN realty URL –Ω–µ –¥–µ–ª–∞–µ–º –ª–∏—à–Ω—é—é –ø—Ä–æ–≤–µ—Ä–∫—É HEAD
                lu = url.lower()
                if ((('easybase.b-cdn.net' in lu and '/realty/' in lu) or ('api.easybase.com.ua' in lu and '/media/realty/' in lu))
                    and not any(x in lu for x in ['.svg', 'favicon.ico', '/avatar/'])):
                    photo_urls.append(url)
                    continue
                if get_media_type(url) == 'photo' or await is_image_url(session, url):
                    photo_urls.append(url)
        logging.info(f"–ù–∞–π–¥–µ–Ω–æ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π: {len(photo_urls)}")
        
        if not photo_urls:
            await loading_msg.delete()
            await message.reply(
                "–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏. üö´\n"
                "–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.",
                reply_markup=get_main_menu()
            )
            return
        
        # –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏
        media = []  # —Ç–æ–ª—å–∫–æ —Ñ–æ—Ç–æ –¥–ª—è –∞–ª—å–±–æ–º–æ–≤
        doc_fallbacks = []  # –¥–æ–∫—É–º–µ–Ω—Ç—ã –¥–ª—è –∫–µ–π—Å–æ–≤ –±–µ–∑ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏
        success_count = 0
        error_count = 0
        
        async with aiohttp.ClientSession() as session:
            for i, url in enumerate(photo_urls, 1):
                logging.info(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–æ—Ç–æ {i}/{len(photo_urls)}: {url}")
                photo_data, error = await download_media(url, session)
                if photo_data:
                    try:
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ñ–æ—Ç–æ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –≤–∞–ª–∏–¥–Ω–æ–µ
                        if photo_data.getbuffer().nbytes > 0:
                            # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π JPEG/PNG URL
                            try:
                                alt_buf = await fetch_alt_image_format(session, url)
                                if alt_buf is not None:
                                    photo_data = alt_buf
                            except Exception:
                                pass
                            if PIL_AVAILABLE:
                                try:
                                    photo_data.seek(0)
                                    img = Image.open(photo_data)
                                    try:
                                        if getattr(img, 'is_animated', False):
                                            img.seek(0)
                                    except Exception:
                                        pass
                                    if img.mode in ('RGBA', 'P'):
                                        img = img.convert('RGB')
                                    buf = BytesIO()
                                    img.save(buf, format='JPEG', quality=90)
                                    buf.seek(0)
                                    input_file = InputFile(buf, filename=f"photo_{i}.jpg")
                                    media.append(InputMediaPhoto(media=input_file))
                                except Exception as ce:
                                    logging.error(f"–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ JPEG –Ω–µ —É–¥–∞–ª–∞—Å—å –¥–ª—è —Ñ–æ—Ç–æ {i}: {ce}")
                                    photo_data.seek(0)
                                    copy_buf = BytesIO(photo_data.read())
                                    copy_buf.seek(0)
                                    # –§–æ–ª–±—ç–∫: –æ—Ç–ø—Ä–∞–≤–∏–º –∫–∞–∫ –¥–æ–∫—É–º–µ–Ω—Ç —Å –∏—Å—Ö–æ–¥–Ω—ã–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ–º
                                    try:
                                        ext = '.jpg'
                                        m = re.search(r"\.([a-z0-9]{3,4})(?:\?|$)", url.lower())
                                        if m:
                                            ext = '.' + m.group(1)
                                    except Exception:
                                        ext = '.jpg'
                                    doc_fallbacks.append((copy_buf, f"photo_{i}{ext}"))
                            else:
                                photo_data.seek(0)
                                copy_buf = BytesIO(photo_data.read())
                                copy_buf.seek(0)
                                try:
                                    ext = '.jpg'
                                    m = re.search(r"\.([a-z0-9]{3,4})(?:\?|$)", url.lower())
                                    if m:
                                        ext = '.' + m.group(1)
                                except Exception:
                                    ext = '.jpg'
                                doc_fallbacks.append((copy_buf, f"photo_{i}{ext}"))
                            success_count += 1
                            logging.info(f"–£—Å–ø–µ—à–Ω–æ –¥–æ–±–∞–≤–ª–µ–Ω–æ —Ñ–æ—Ç–æ {i}")
                        else:
                            error_count += 1
                            logging.error(f"–§–æ—Ç–æ {i} –∏–º–µ–µ—Ç –Ω—É–ª–µ–≤–æ–π —Ä–∞–∑–º–µ—Ä")
                    except Exception as e:
                        error_count += 1
                        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ —Ñ–æ—Ç–æ {i}: {str(e)}")
                else:
                    error_count += 1
                    logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–æ—Ç–æ {i}: {error}")
        
        logging.info(f"–£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ñ–æ—Ç–æ: {success_count}, –æ—à–∏–±–æ–∫: {error_count}")
        
        if media:
            try:
                await loading_msg.delete()
            except Exception:
                pass
            loading_msg = None
            try:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∞–ª–∏–¥–Ω—ã—Ö —Ñ–æ—Ç–æ
                if len(media) == 0:
                    raise Exception("–ù–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏")
                
                if len(media) == 1:
                    # –ï—Å–ª–∏ –Ω–∞–π–¥–µ–Ω–æ —Ç–æ–ª—å–∫–æ –æ–¥–Ω–æ —Ñ–æ—Ç–æ, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –µ–≥–æ –∫–∞–∫ –æ–¥–∏–Ω–æ—á–Ω–æ–µ
                    logging.info("–û—Ç–ø—Ä–∞–≤–∫–∞ –æ–¥–∏–Ω–æ—á–Ω–æ–≥–æ —Ñ–æ—Ç–æ")
                    await message.reply_photo(
                        photo=media[0].media,
                        caption=f"‚úÖ –§–æ—Ç–æ —Å–∫–∞—á–∞–Ω–æ!\n–ò—Å—Ç–æ—á–Ω–∏–∫: {content[:50]}...",
                        reply_markup=get_main_menu()
                    )
                    logging.info("–£—Å–ø–µ—à–Ω–æ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ –æ–¥–∏–Ω–æ—á–Ω–æ–µ —Ñ–æ—Ç–æ")
                    return
                elif 2 <= len(media) <= 10:
                    # –ï—Å–ª–∏ –Ω–∞–π–¥–µ–Ω–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ñ–æ—Ç–æ, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –∫–∞–∫ –∞–ª—å–±–æ–º
                    logging.info(f"–û—Ç–ø—Ä–∞–≤–∫–∞ –∞–ª—å–±–æ–º–∞ –∏–∑ {len(media)} —Ñ–æ—Ç–æ")
                    await message.reply_media_group(media)
                    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã-—Ñ–æ–ª–±—ç–∫–∏ (–µ—Å–ª–∏ –µ—Å—Ç—å)
                    for idx, (buf, fname) in enumerate(doc_fallbacks, 1):
                        try:
                            buf.seek(0)
                            await message.reply_document(InputFile(buf, filename=fname))
                            await asyncio.sleep(0.2)
                        except Exception as e:
                            logging.error(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞ {idx}: {e}")
                    await message.reply(
                        f"‚úÖ –°–∫–∞—á–∞–Ω–æ {len(media)} —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π!\n"
                        f"–ò—Å—Ç–æ—á–Ω–∏–∫: {content[:50]}...\n"
                        f"–î–æ–∫—É–º–µ–Ω—Ç–æ–≤ (fallback): {len(doc_fallbacks)}",
                        reply_markup=get_main_menu()
                    )
                    logging.info(f"–£—Å–ø–µ—à–Ω–æ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω –∞–ª—å–±–æ–º –∏–∑ {len(media)} —Ñ–æ—Ç–æ")
                    return
                else:
                    # –ï—Å–ª–∏ —Ñ–æ—Ç–æ –±–æ–ª—å—à–µ 10, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤—Å–µ –ø–æ –±–∞—Ç—á–∞–º –ø–æ 10
                    total = len(media)
                    logging.info(f"–û—Ç–ø—Ä–∞–≤–∫–∞ –∞–ª—å–±–æ–º–∞ –±–∞—Ç—á–∞–º–∏ –ø–æ 10 (–≤—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ: {total})")
                    for start in range(0, total, 10):
                        batch = media[start:start+10]
                        try:
                            await message.reply_media_group(batch)
                            await asyncio.sleep(0.5)
                        except Exception as e:
                            logging.error(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –±–∞—Ç—á–∞ {start//10+1}: {e}")
                    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã-—Ñ–æ–ª–±—ç–∫–∏ (–µ—Å–ª–∏ –µ—Å—Ç—å)
                    for idx, (buf, fname) in enumerate(doc_fallbacks, 1):
                        try:
                            buf.seek(0)
                            await message.reply_document(InputFile(buf, filename=fname))
                            await asyncio.sleep(0.2)
                        except Exception as e:
                            logging.error(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞ {idx}: {e}")
                    await message.reply(
                        f"‚úÖ –°–∫–∞—á–∞–Ω–æ –∏ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ {total} —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π!\n"
                        f"–ò—Å—Ç–æ—á–Ω–∏–∫: {content[:50]}...\n"
                        f"–î–æ–∫—É–º–µ–Ω—Ç–æ–≤ (fallback): {len(doc_fallbacks)}",
                        reply_markup=get_main_menu()
                    )
                    logging.info("–£—Å–ø–µ—à–Ω–æ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω—ã –≤—Å–µ –±–∞—Ç—á–∏ —Ñ–æ—Ç–æ")
                    return
            except Exception as e:
                logging.error(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ —Ñ–æ—Ç–æ: {str(e)}")
            
            # –ï—Å–ª–∏ –≤–∏–¥–µ–æ –Ω–µ –Ω–∞—à–ª–∏, –∏—â–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            if loading_msg is not None:
                try:
                    await loading_msg.edit_text(" –í–∏–¥–µ–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –∏—â—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è...")
                except Exception:
                    pass
            # –Ω–∏–∂–µ —É—Å—Ç–∞—Ä–µ–≤—à–∞—è –≤–µ—Ç–∫–∞ –¥–ª—è HTML-—Ç–µ–∫—Å—Ç–∞, –ø—Ä–æ–ø—É—Å—Ç–∏–º –¥–ª—è URL —Å—Ü–µ–Ω–∞—Ä–∏—è
            
        else:
            # –°–æ–∑–¥–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –æ –∑–∞–≥—Ä—É–∑–∫–µ
            loading_msg = await show_loading_animation(message, "–∫–æ–Ω—Ç–µ–Ω—Ç–∞")
            if loading_msg is None:
                await message.reply("–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —Å–æ–æ–±—â–µ–Ω–∏—è –æ –∑–∞–≥—Ä—É–∑–∫–µ. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞.")
                return
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ç–µ–∫—Å—Ç HTML-–∫–æ–¥–æ–º
            is_html = '<' in content and '>' in content
            
            if is_html:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –ø–æ URL/HTML
                media_type = get_media_type(content)
            if media_type == 'video':
                # –ü—ã—Ç–∞–µ–º—Å—è —Å–∫–∞—á–∞—Ç—å –≤–∏–¥–µ–æ –Ω–∞–ø—Ä—è–º—É—é
                await process_video_url(message, content, loading_msg)
            else:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º Playwright –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
                if loading_msg is not None:
                    try:
                        await loading_msg.edit_text(" –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –º–µ–¥–∏–∞...")
                    except Exception:
                        pass
                
                # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –≤–∏–¥–µ–æ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ
                video_url, _ = await fetch_media_url(content)
                if video_url:
                    await process_video_url(message, video_url, loading_msg)
                    return
                
                # –ï—Å–ª–∏ –≤–∏–¥–µ–æ –Ω–µ –Ω–∞—à–ª–∏, –∏—â–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                urls = await extract_potential_urls(content)
                if urls:
                    await process_media_urls(message, urls, loading_msg)
                else:
                    if loading_msg is not None:
                        try:
                            await loading_msg.edit_text("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –º–µ–¥–∏–∞ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ ")
                        except Exception:
                            pass
                
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏—è: {str(e)}")
        if 'loading_msg' in locals() and loading_msg is not None:
            try:
                await loading_msg.edit_text(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {str(e)} ")
            except Exception:
                pass
    finally:
        if 'loading_msg' in locals() and loading_msg is not None:
            try:
                await bot.delete_message(chat_id=loading_msg.chat.id, message_id=loading_msg.message_id)
            except Exception:
                pass

# –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∏–¥–µ–æ –ø–æ URL
async def process_video_url(message: Message, video_url: str, loading_msg: Message):
    try:
        await loading_msg.edit_text("üì• –°–∫–∞—á–∏–≤–∞—é –≤–∏–¥–µ–æ...")
        
        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ –¥–ª—è –æ–±—Ö–æ–¥–∞ –∑–∞—â–∏—Ç—ã
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Referer': 'https://motherless.com/',
            'Accept': 'video/webm,video/ogg,video/*;q=0.9,application/ogg;q=0.7,audio/*;q=0.6,*/*;q=0.5',
            'Accept-Language': 'en-US,en;q=0.5',
            'Range': 'bytes=0-',
            'Origin': 'https://motherless.com',
            'DNT': '1',
        }
        
        # –°–æ–∑–¥–∞–µ–º —Å–µ—Å—Å–∏—é –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
        timeout = aiohttp.ClientTimeout(total=300, connect=30)
        connector = aiohttp.TCPConnector(force_close=True, enable_cleanup_closed=True)
        
        async with aiohttp.ClientSession(timeout=timeout, connector=connector) as session:
            try:
                # –°–∫–∞—á–∏–≤–∞–µ–º –≤–∏–¥–µ–æ —Å –Ω–∞—à–∏–º–∏ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏
                video_data, error = await download_media(video_url, session, headers=headers)
                
                if error:
                    # –ï—Å–ª–∏ –æ—à–∏–±–∫–∞ —Å–≤—è–∑–∞–Ω–∞ —Å –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–µ–π, —Å–æ–æ–±—â–∞–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
                    if '—Ç—Ä–µ–±—É–µ—Ç—Å—è –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è' in error.lower():
                        await message.reply(
                            "‚ö†Ô∏è –≠—Ç–æ –≤–∏–¥–µ–æ –¥–æ—Å—Ç—É–ø–Ω–æ —Ç–æ–ª—å–∫–æ –¥–ª—è –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π Motherless.\n\n"
                            "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–æ–π–¥–∏—Ç–µ –≤ –∞–∫–∫–∞—É–Ω—Ç –Ω–∞ —Å–∞–π—Ç–µ –∏ –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞.",
                            reply_markup=get_main_menu()
                        )
                    else:
                        await message.reply(f"‚ùå {error}", reply_markup=get_main_menu())
                    
                    try:
                        await loading_msg.delete()
                    except:
                        pass
                    return
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ñ–∞–π–ª–∞
                file_ext = 'mp4'  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏—Å–ø–æ–ª—å–∑—É–µ–º mp4
                if '.' in video_url:
                    ext = video_url.split('.')[-1].lower()
                    if ext in ['mp4', 'webm', 'mov', 'avi', 'mkv', 'flv']:
                        file_ext = ext
                
                # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
                temp_file = f"temp_video_{int(time.time())}.{file_ext}"
                try:
                    with open(temp_file, 'wb') as f:
                        f.write(video_data.getbuffer())
                    
                    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤–∏–¥–µ–æ
                    await loading_msg.edit_text("üì§ –û—Ç–ø—Ä–∞–≤–ª—è—é –≤–∏–¥–µ–æ...")
                    
                    try:
                        # –ü—Ä–æ–±—É–µ–º –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –∫–∞–∫ –≤–∏–¥–µ–æ
                        with open(temp_file, 'rb') as video_file:
                            await message.reply_video(
                                video=video_file,
                                caption=f"üé• –í–∏–¥–µ–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ!\n–ò—Å—Ç–æ—á–Ω–∏–∫: {video_url[:100]}",
                                reply_markup=get_main_menu(),
                                supports_streaming=True
                            )
                    except Exception as e:
                        # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –∫–∞–∫ –≤–∏–¥–µ–æ, –ø—Ä–æ–±—É–µ–º –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –∫–∞–∫ –¥–æ–∫—É–º–µ–Ω—Ç
                        logging.error(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤–∏–¥–µ–æ: {str(e)}, –ø—Ä–æ–±—É–µ–º –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –∫–∞–∫ –¥–æ–∫—É–º–µ–Ω—Ç...")
                        with open(temp_file, 'rb') as video_file:
                            await message.reply_document(
                                document=video_file,
                                caption=f"üìÅ –í–∏–¥–µ–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ –∫–∞–∫ –¥–æ–∫—É–º–µ–Ω—Ç\n–ò—Å—Ç–æ—á–Ω–∏–∫: {video_url[:100]}",
                                reply_markup=get_main_menu()
                            )
                    
                    await loading_msg.delete()
                    
                except Exception as e:
                    logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏/–æ—Ç–ø—Ä–∞–≤–∫–µ –≤–∏–¥–µ–æ: {str(e)}", exc_info=True)
                    await message.reply("‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∏–¥–µ–æ. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.")
                
                # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª, –µ—Å–ª–∏ –æ–Ω —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
                try:
                    import os
                    if os.path.exists(temp_file):
                        os.remove(temp_file)
                except Exception as e:
                    logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞: {str(e)}")
                    
            except Exception as e:
                logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∏–¥–µ–æ: {str(e)}", exc_info=True)
                await message.reply(f"‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {str(e)}")
                try:
                    await loading_msg.delete()
                except:
                    pass
                    
    except Exception as e:
        logging.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ process_video_url: {str(e)}", exc_info=True)
        try:
            await message.reply("‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∏–¥–µ–æ. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.")
            try:
                await loading_msg.delete()
            except:
                pass
        except Exception as e2:
            logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ —Å–æ–æ–±—â–µ–Ω–∏—è –æ–± –æ—à–∏–±–∫–µ: {str(e2)}")

# –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–Ω–ª–∞–π–Ω-–∫–Ω–æ–ø–æ–∫
async def process_callback(callback: CallbackQuery):
    user_id = callback.from_user.id
    update_user_activity(user_id)
    action = callback.data

    if action == 'main_menu':
        await callback.message.edit_text(
            "–û—Ç–ø—Ä–∞–≤—å—Ç–µ HTML-–∫–æ–¥ —Å—Ç—Ä–∞–Ω–∏—Ü—ã, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π –≤–∏–¥–µ–æ. üìÑ",
            reply_markup=get_main_menu()
        )
    elif action == 'send_html':
        await callback.message.edit_text(
            "–û—Ç–ø—Ä–∞–≤—å—Ç–µ HTML-–∫–æ–¥ —Å—Ç—Ä–∞–Ω–∏—Ü—ã, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π –≤–∏–¥–µ–æ. üìÑ",
            reply_markup=get_main_menu()
        )
    elif action == 'support':
        await callback.message.edit_text(
            "üåü *–ü–æ–¥–¥–µ—Ä–∂–∫–∞*\n\n"
            "–ï—Å–ª–∏ –±–æ—Ç –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –∏–ª–∏ —É –≤–∞—Å –µ—Å—Ç—å –≤–æ–ø—Ä–æ—Å—ã, –ø–∏—à–∏—Ç–µ: @makar2108 üì©\n"
            "‚ö†Ô∏è Telegram –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ—Ç —Ä–∞–∑–º–µ—Ä —Å–∫–∞—á–∏–≤–∞–µ–º—ã—Ö —Ñ–∞–π–ª–æ–≤ –¥–æ 50 –ú–ë.\n\n"
            "–ü–æ–¥–¥–µ—Ä–∂–∏—Ç–µ –ø—Ä–æ–µ–∫—Ç –¥–æ–±—Ä–æ–≤–æ–ª—å–Ω—ã–º –ø–æ–∂–µ—Ä—Ç–≤–æ–≤–∞–Ω–∏–µ–º:\n"
            "BEP-20 USDT: `0xc4b648A590A61F2F1d8b99f41248066533428471` üí∏",
            parse_mode='Markdown',
            reply_markup=get_main_menu()
        )
    elif action == 'admin_stats':
        if user_id != ADMIN_ID:
            await callback.message.edit_text("–î–æ—Å—Ç—É–ø–Ω–æ —Ç–æ–ª—å–∫–æ –∞–¥–º–∏–Ω—É. üîê", reply_markup=get_main_menu())
            await callback.answer()
            return
        daily, weekly, total = get_user_stats()
        await callback.message.edit_text(
            f"üìä *–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π*\n\n"
            f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏:\n"
            f"- –ó–∞ –¥–µ–Ω—å: {daily}\n"
            f"- –ó–∞ –Ω–µ–¥–µ–ª—é: {weekly}\n"
            f"- –ó–∞ –≤—Å—ë –≤—Ä–µ–º—è: {total}",
            parse_mode='Markdown',
            reply_markup=get_admin_menu()
        )
    elif action == 'admin_status':
        if user_id != ADMIN_ID:
            await callback.message.edit_text("–î–æ—Å—Ç—É–ø–Ω–æ —Ç–æ–ª—å–∫–æ –∞–¥–º–∏–Ω—É. üîê", reply_markup=get_main_menu())
            await callback.answer()
            return
        await callback.message.edit_text(
            f"üöÄ *–°—Ç–∞—Ç—É—Å –±–æ—Ç–∞*\n\n"
            f"–ë–æ—Ç —Ä–∞–±–æ—Ç–∞–µ—Ç!\n"
            f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∑–∞–ø—Ä–æ—Å–æ–≤: {request_count} üìä",
            parse_mode='Markdown',
            reply_markup=get_admin_menu()
        )

    await callback.answer()

# Register handlers
dp.message.register(send_welcome, Command(commands=['start']))
dp.message.register(send_support, Command(commands=['support']))
dp.message.register(admin_status, Command(commands=['admin']))
dp.message.register(handle_html, F.content_type == ContentType.TEXT)
dp.callback_query.register(process_callback)

async def on_startup():
    logging.info('–ë–æ—Ç –∑–∞–ø—É—â–µ–Ω üöÄ')

async def main():
    dp.startup.register(on_startup)
    await dp.start_polling(bot, drop_pending_updates=True)

if __name__ == '__main__':
    asyncio.run(main())